[
  {
    "title": "Efficient and Robust Shoveling Control System based on Semantic Elevation Mapping for Unmanned Loaders",
    "link": "https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence",
    "authors": "<b>Guangda Chen</b>, Zhiwen Zhang, Lin Cheng, Cheng Jin, Shunyi Yao, Yue Wang, Rong Xiong and Yingfeng Chen.",
    "venue": "Engineering Applications of Artificial Intelligence",
    "venueLink": "https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence",
    "rating": "(CCF-C), (2026, <em>Accept</em>. IF: 8)",
    "rating_link": "https://www.caa.org.cn/Uploads/image/file/20230414/20230414170847_65463.pdf#page=15",
    "bibtex": "",
    "abstract": ""
  },
  {
    "title": "Modeling and Control of General Hydraulic Excavator for Human-in-the-loop Automation",
    "link": "https://ieeexplore.ieee.org/document/10356425",
    "authors": "<b>Guangda Chen</b>, Yinghao Gan, J. Chen, S. Shi, W. Chen, <a href='https://scholar.google.com/citations?user=SSBrkpMAAAAJ&hl=en'>Y. Chen</a>, <a href='https://scholar.google.com/citations?hl=en&user=1hI9bqUAAAAJ'>Rong Xiong</a> and Changjie Fan.",
    "venue": "ICTAI 2023",
    "venueLink": "https://ictai.computer.org/2023/",
    "rating": "(CCF-C)",
    "rating_link": "https://ccf.atom.im/",
    "bibtex": "@INPROCEEDINGS{10356425,\n author={Chen, Guangda and Gan, Yinghao and Chen, Jiayi and Shi, Shuanwu and Chen, Wei and Chen, Yingfeng and Xiong, Rong and Fan, Changjie},\n booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)},\n title={Modeling and Control of General Hydraulic Excavator for Human-in-the-loop Automation},\n year={2023},\n pages={708-716},\n doi={10.1109/ICTAI59109.2023.00110}\n}",
    "abstract": "As labor shortages and safety regulations become more prominent, the need for human-in-the-loop automation of excavators is increasing. To meet this demand, we have developed a comprehensive modeling method for the excavator arm using nonlinear optimization approaches, including a simplified model that maps the task space to the joint space, as well as an equivalent model that maps the joint space to the actuator space. These models were then used to build a feedforward-PID joint velocity controller and a joint trajectory controller combined with position feedback, which forms the core of our proposed semi-automatic control system for the excavator arm. Our deployment scheme is simple and efficient, and has been deployed on two excavators of different makes and sizes. Experiments show that our deployment scheme performs well on both excavators, with an average error of 0.05 rad/s for the velocity controller and less than 5 cm for the trajectory controller. Using our semi-automatic system, we have completed demonstration experiments for precise digging and grading operations. A demonstration video can be found at https://youtu.be/N6I0WZGSF68.",
    "keywords": "",
    "pdf": "pdf/Modeling and Control of General Hydraulic Excavator for Human-in-the-loop Automation.pdf",
    "demo": "https://youtu.be/N6I0WZGSF68"
  },
  {
    "title": "Robot Navigation in Complex and Dynamic Pedestrian Scenarios",
    "sub_title": "复杂动态行人场景下的机器人导航",
    "link": "https://doi.org/10.27517/d.cnki.gzkju.2021.000357",
    "authors": "<b>Guangda Chen</b>.",
    "venue": "University of Science and Technology of China",
    "rating": ". Hefei, China. June, 2021.",
    "award": "PhD Thesis",
    "bibtex": "@phdthesis{cgd-phd,\n  title = {复杂动态行人场景下的机器人导航},\n  author = {陈广大},\n  year = {2021},\n  school = {中国科学技术大学},\n  ADDRESS    = \"合肥\"\n}",
    "pdf": "pdf/phd_cgd.pdf",
    "slides": "pdf/phd_ppt.pdf"
  },
  {
    "title": "Accurate Intrinsic and Extrinsic Calibration of RGB-D Cameras with GP-based Depth Correction",
    "link": "https://ieeexplore.ieee.org/document/8588983",
    "authors": "<b>Guangda Chen</b>, Guowei Cui, Zhongxiao Jin, <a href='https://wufeng02.github.io/'>Feng Wu</a> and Xiaoping Chen.",
    "venue": "IEEE Sensors Journal",
    "venueLink": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7361",
    "rating": "(CAA-B), (Volume: 19, Issue: 7, April, 1, 2019. IF: 4.5)",
    "rating_link": "https://www.caa.org.cn/Uploads/image/file/20230414/20230414170847_65463.pdf#page=15",
    "bibtex": "@Article{chen2019accurate,\n title = {Accurate Intrinsic and Extrinsic Calibration of {RGB}-D Cameras With {GP}-Based Depth Correction},\n author = {Guangda Chen and Guowei Cui and Zhongxiao Jin and Feng Wu and Xiaoping Chen},\n journal = {IEEE Sensors Journal},\n volume = {19},\n number = {7},\n pages = {2685--2694},\n year = 2019,\n month = {apr},\n publisher = {IEEE},\n doi = {10.1109/jsen.2018.2889805},\n url = {https://doi.org/10.1109%2Fjsen.2018.2889805}\n}",
    "abstract": "In recent years, more and more robots have been equipped with low-cost RGB-D sensors, such as Microsoft Kinect and Intel Realsense, for safe navigation and active interaction with objects and people. In order to obtain more accurate and reliable fused color and depth information (coloured point clouds), not only the intrinsic and extrinsic parameters of color and depth sensor should be precisely calibrated, but also the external corrections of depth measurements are required. In this paper, using motion capture system, we propose a reliable calibration framework that enables the precise estimation of the intrinsic and extrinsic parameters of RGB-D sensors and provide a model-free depth calibration method based on heteroscedastic Gaussian Processes. Compared with the existing depth correction techniques, our method can simultaneously estimate the mean and variance of the depth error at different measurement distances, i.e., the probability distribution of the depth error relative to the measured distance, which is essential in the state estimation problems. To verify the effectiveness of our approach, we conduct a thorough qualitative and quantitative analysis of the major steps of our calibration method, and compare our experimental results with other related work. Furthermore, we demonstrate an experiment about the overall improvement of visual SLAM with a Kinect device calibrated by our calibration technique.",
    "keywords": "RGB-D cameras, calibration, motion capture system",
    "pdf": "pdf/rgbd_cal_j.pdf",
    "pdf2": "pdf/jsen.pdf"
  },
  {
    "title": "Robot Navigation with Map-Based Deep Reinforcement Learning",
    "link": "https://ieeexplore.ieee.org/document/9238090",
    "authors": "<b>Guangda Chen</b>, Lifan Pan, Y. C., P. X., Z. W., P. W., <a href='http://staff.ustc.edu.cn/~jianmin/'>Jianmin Ji</a> and Xiaoping Chen.",
    "venue": "ICNSC 2020",
    "venueLink": "http://www.icnsc2020.org/",
    "rating": "(CAA-B)",
    "rating_link": "https://www.caa.org.cn/Uploads/image/file/20230213/20230213163755_94080.pdf#page=21",
    "bibtex": "@InProceedings{chen2020robot,\n title = {Robot Navigation with Map-Based Deep Reinforcement Learning},\n author = {Chen, Guangda and Pan, Lifan and Chen, Yu'an and Xu, Pei and Wang, Zhiqiang and Wu, Peichen and Ji, Jianmin and Chen, Xiaoping},\n year = {2020},\n pages = {1-6},\n address = {Nanjing, China},\n doi = {10.1109/ICNSC48988.2020.9238090},\n organization = {IEEE}\n}",
    "abstract": "This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing  DRL-based models in many indicators.",
    "keywords": "robot navigation, obstacle avoidance, reinforcement learning, occupancy map",
    "pdf": "pdf/ICNSC_2020_paper_11.pdf",
    "demo": "https://youtu.be/Eq4AjsFH_cU",
    "slides": "pdf/ICNSC2020slide.pdf",
    "award": "Best Student Paper Award",
    "award_link": "pdf/ICNSC2020Award.pdf"
  },
  {
    "title": "Deep Reinforcement Learning of Map-Based Obstacle Avoidance for Mobile Robot Navigation",
    "link": "https://link.springer.com/article/10.1007/s42979-021-00817-z",
    "authors": "<b>Guangda Chen</b>, Lifan Pan, Y. C., P. X., Z. W., P. W., Jianmin Ji and Xiaoping Chen.",
    "venue": "SN Computer Science",
    "venueLink": "https://www.springer.com/journal/42979",
    "rating": "(Volume: 2 , Issue: 6 , August, 18, 2021)",
    "rating_link": "",
    "bibtex": "@article{chen2021deep,\n title = {Deep Reinforcement Learning of Map-Based Obstacle Avoidance for Mobile Robot Navigation},\n author = {Chen, Guangda and Pan, Lifan and Chen, Yu'an and Xu, Pei and Wang, Zhiqiang and Wu, Peichen and Ji, Jianmin and Chen, Xiaoping},\n journal = {SN Computer Science},\n volume = {2},\n number = {6},\n pages={1--14},\n year = {2021},\n month = {August},\n publisher = {Springer},\n doi = {10.1007/s42979-021-00817-z},\n url = {https://doi.org/10.1007/s42979-021-00817-z}\n} ",
    "abstract": "Autonomous and safe navigation in complex environments without collisions is particularly important for mobile robots. In this paper, we propose an end-to-end deep reinforcement learning method for mobile robot navigation with map-based obstacle avoidance. Using the experience collected in the simulation environment, a convolutional neural network is trained to predict the proper steering operation of the robot based on its egocentric local grid maps, which can accommodate various sensors and fusion algorithms. We use dueling double DQN with prioritized experienced replay technology to update parameters of the network and integrate curriculum learning techniques to enhance its performance. The trained deep neural network is then transferred and executed on a real-world mobile robot to guide it to avoid local obstacles for long-range navigation. The qualitative and quantitative evaluations of the new approach were performed in simulations and real robot experiments. The results show that the end-to-end map-based obstacle avoidance model is easy to deploy, without any fine-tuning, robust to sensor noise, compatible with different sensors, and better than other related DRL-based models in many evaluation indicators.",
    "keywords": "robot navigation, obstacle avoidance, deep reinforcement learning, grid map",
    "pdf": "pdf/Chen2021_Article_DeepReinforcementLearningOfMap.pdf"
  },


  {
    "title": "Distributed Non-Communicating Multi-Robot Collision Avoidance via Map-Based Deep Reinforcement Learning",
    "link": "https://www.mdpi.com/1424-8220/20/17/4836",
    "authors": "<b>Guangda Chen</b>, Shunyi Yao, Jun Ma, L. P., Y. C., P. X., Jianmin Ji and Xiaoping Chen.",
    "venue": "Sensors",
    "rating": "(Volume: 20, Issue: 17 , August, 27, 2020. IF: 3.5)",
    "venueLink": "https://www.mdpi.com/journal/sensors",
    "bibtex": "@Article{chen2020distributed,\n title = {Distributed Non-Communicating Multi-Robot Collision Avoidance via Map-Based Deep Reinforcement Learning},\n author = {Chen, Guangda and Yao, Shunyi and Ma, Jun and Pan, Lifan and Chen, Yu'an and Xu, Pei and Ji, Jianmin and Chen, Xiaoping},\n journal = {Sensors},\n volume = {20},\n number = {17},\n pages = {4836},\n year = {2020},\n publisher = {Multidisciplinary Digital Publishing Institute},\n doi = {10.3390/s20174836},\n url = {https://www.mdpi.com/1424-8220/20/17/4836}\n}",
    "abstract": "It is challenging to avoid obstacles safely and efficiently for multiple robots of different shapes in distributed and communication-free scenarios, where robots do not communicate with each other and only sense other robots' positions and obstacles around them. Most existing multi-robot collision avoidance systems either require communication between robots or require expensive movement data of other robots, like velocities, accelerations and paths. In this paper, we propose a map-based deep reinforcement learning approach for multi-robot collision avoidance in a distributed and communication-free environment. We use the egocentric local grid map of a robot to represent the environmental information around it including its shape and observable appearances of other robots and obstacles, which can be easily generated by using multiple sensors or sensor fusion. Then we apply the distributed proximal policy optimization (DPPO) algorithm to train a convolutional neural network that directly maps three frames of egocentric local grid maps and the robot's relative local goal positions into low-level robot control commands. Compared to other methods, the map-based approach is more robust to noisy sensor data, does not require robots' movement data and considers sizes and shapes of related robots, which make it to be more efficient and easier to be deployed to real robots. We first train the neural network in a specified simulator of multiple mobile robots using DPPO, where a multi-stage curriculum learning strategy for multiple scenarios is used to improve the performance. Then we deploy the trained model to real robots to perform collision avoidance in their navigation without tedious parameter tuning. We evaluate the approach with multiple scenarios both in the simulator and on four differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient and outperforms existing DRL-based approaches in many indicators. We also conduct ablation studies showing the positive effects of using egocentric grid maps and multi-stage curriculum learning.",
    "keywords": "multi-robot navigation, distributed collision avoidance, deep reinforcement learning",
    "pdf": "pdf/DRL_NAV_sensors.pdf",
    "demo": "https://youtu.be/KOb1q23L7-U",
    "demo2": "https://www.bilibili.com/video/BV12f4y1Q7cx",
    "demo3": "https://www.bilibili.com/video/BV12v411C7sM"
  },
  {
    "title": "Crowd-Aware Robot Navigation for Pedestrians with Multiple Collision Avoidance Strategies via Map-based Deep Reinforcement Learning",
    "link": "http://dx.doi.org/10.1109/IROS51168.2021.9636579",
    "authors": "Shunyi Yao∗, <b>Guangda Chen</b>∗, Quecheng Qiu, Jun Ma, Xiaoping Chen and Jianmin Ji.",
    "venue": "IROS 2021",
    "venueLink": "https://www.iros2021.org/",
    "rating": "(TH-B)",
    "rating_link": "https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf#page=12",
    "bibtex": "@inproceedings{yao2021crowd,\n title={Crowd-aware robot navigation for pedestrians with multiple collision avoidance strategies via map-based deep reinforcement learning},\n author={Yao, Shunyi and Chen, Guangda and Qiu, Quecheng and Ma, Jun and Chen, Xiaoping and Ji, Jianmin},\n booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n pages={8144--8150},\n year={2021},\n organization={IEEE}\n}",
    "abstract": "It is challenging for a mobile robot to navigate through human crowds. Existing approaches usually assume that pedestrians follow a predefined collision avoidance strategy, like social force model (SFM) or optimal reciprocal collision avoidance (ORCA). However, their performances commonly need to be further improved for practical applications, where pedestrians follow multiple different collision avoidance strategies. In this paper, we propose a map-based deep reinforcement learning approach for crowd-aware robot navigation with various pedestrians. We use the sensor map to represent the environmental information around the robot, including its shape and observable appearances of obstacles. We also introduce the pedestrian map that specifies the movements of pedestrians around the robot. By applying both maps as inputs of the neural network, we show that a navigation policy can be trained to better interact with pedestrians following different collision avoidance strategies. We evaluate our approach under multiple scenarios both in the simulator and on an actual robot. The results show that our approach allows the robot to successfully interact with various pedestrians and outperforms compared methods in terms of the success rate.",
    "pdf": "pdf/IROS_2021_PedNav.pdf",
    "demo": "https://www.bilibili.com/video/BV1Vb4y1D7R6"
  },
  {
    "title": "Multi-Robot Collision Avoidance with Map-Based Deep Reinforcement Learning",
    "link": "https://ieeexplore.ieee.org/abstract/document/9288300/",
    "authors": "Shunyi Yao∗, <b>Guangda Chen</b>∗, Lifan Pan, Jun Ma, Jianmin Ji and Xiaoping Chen.",
    "venue": "ICTAI 2020",
    "venueLink": "https://ictai2020.org/index.html",
    "rating": "(CCF-C)",
    "rating_link": "https://ccf.atom.im/",
    "bibtex": "@InProceedings{yao2020multi,\n author = {Yao, Shunyi and Chen, Guangda and Pan, Lifan and Ma, Jun and Ji, Jianmin and Chen, Xiaoping},\n booktitle = {Proceedings of the 32th International Conference on Tools with Artificial Intelligence (ICTAI)},\n title = {Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning},\n pages = {532--539},\n year = {2020},\n organization = {IEEE}\n}",
    "abstract": "Multi-robot collision avoidance in a communicationfree environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a mapbased deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. Compared to other methods, the map-based approach is more robust to noisy sensor data and does not require the expensive movement data of other robots, like velocities, accelerations and paths. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO), where curriculum learning strategy is used to accelerate the training process. Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",
    "keywords": "multi-robots collision avoidance, reinforcement learning, egocentric grid map",
    "pdf": "pdf/ICTAI_2020.pdf",
    "demo": "https://youtu.be/jcLKlEXuFuk"
  },
  {
    "title": "DRQN-based 3D Obstacle Avoidance with a Limited Field of View",
    "link": "https://ieeexplore.ieee.org/abstract/document/9635949",
    "authors": "Yu'an CHen, <b>Guangda Chen</b>, Lifan Pan, Jun Ma, Yu Zhang, Yanyong Zhang and Jianmin Ji.",
    "venue": "IROS 2021",
    "venueLink": "https://ieeexplore.ieee.org/xpl/conhome/9635848/proceeding",
    "rating": "(TH-B)",
    "rating_link": "https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf#page=12",
    "bibtex": "@inproceedings{chen2021drqn,\n title={DRQN-based 3D obstacle avoidance with a limited field of view},\n author={Chen, Yu'an and Chen, Guangda and Pan, Lifan and Ma, Jun and Zhang, Yu and Zhang, Yanyong and Ji, Jianmin},\n booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n pages={8137--8143},\n year={2021},\n organization={IEEE}\n}",
    "abstract": "In this paper, we propose a map-based end-to-end DRL approach for three-dimensional (3D) obstacle avoidance in a partially observed environment, which is applied to achieve autonomous navigation for an indoor mobile robot using a depth camera with a narrow field of view. We first train a neural network with LSTM units in a 3D simulator of mobile robots to approximate the Q-value function in double DRQN. We also use a curriculum learning strategy to accelerate and stabilize the training process. Then we deploy the trained model to a real robot to perform 3D obstacle avoidance in its navigation. We evaluate the proposed approach both in the simulated environment and on a robot in the real world. The experimental results show that the approach is efficient and easy to be deployed, and it performs well for 3D obstacle avoidance with a narrow observation angle, which outperforms other existing DRL-based models by 15.5% on success rate.",
    "pdf": "pdf/IROS_2021_DRQNNav.pdf",
    "demo": "https://youtu.be/_Y9l6hEopyk"
  },
  {
    "title": "Learning to Socially Navigate in Pedestrian-rich Environments with Interaction Capacity",
    "link": "https://ieeexplore.ieee.org/document/9811662",
    "authors": "Quecheng Qiu, Shunyi Yao, Jing Wang, Jun Ma, <b>Guangda Chen</b> and Jianmin Ji.",
    "venue": "ICRA 2022",
    "venueLink": "https://ieeexplore.ieee.org/xpl/conhome/9811522/proceeding",
    "rating": "(TH-A)",
    "rating_link": "https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf#page=11",
    "bibtex": "@inproceedings{qiu2022learning,\n title={Learning to socially navigate in pedestrian-rich environments with interaction capacity},\n author={Qiu, Quecheng and Yao, Shunyi and Wang, Jing and Ma, Jun and Chen, Guangda and Ji, Jianmin},\n  booktitle={2022 International Conference on Robotics and Automation (ICRA)},\n pages={279--285},\n year={2022},\n organization={IEEE}\n}",
    "abstract": "Existing navigation policies for autonomous robots tend to focus on collision avoidance while ignoring human-robot interactions in social life. For instance, robots can pass along the corridor safer and easier if pedestrians notice them. Sounds have been considered as an efficient way to attract the attention of pedestrians, which can alleviate the freezing robot problem. In this work, we present a new deep reinforcement learning (DRL) based social navigation approach for autonomous robots to move in pedestrian-rich environments with interaction capacity. Most existing DRL based methods intend to train a general policy that outputs both navigation actions, i.e., expected robot's linear and angular velocities, and interaction actions, i.e., the beep action, in the context of reinforcement learning. Different from these methods, we intend to train the policy via both supervised learning and reinforcement learning. In specific, we first train an interaction policy in the context of supervised learning, which provides a better understanding of the social situation, then we use this interaction policy to train the navigation policy via multiple reinforcement learning algorithms. We evaluate our approach in various simulation environments and compare it to other methods. The experimental results show that our approach outperforms others in terms of the success rate. We also deploy the trained policy on a real-world robot, which shows a nice performance in crowded environments.",
    "pdf": "pdf/ICRA2022_BEEP_FINAL_06_03.pdf"
  },
  {
    "title": "Training a Non-Cooperator to Identify Vulnerabilities and Improve Robustness for Robot Navigation",
    "link": "https://ieeexplore.ieee.org/document/10147348",
    "authors": "Quecheng Qiu, Xuyang Zhang, Shunyi Yao, Yu'an Chen, <b>Guangda Chen</b>, Bei Hua and Jianmin Ji.",
    "venue": "IEEE Robotics and Automation Letters",
    "rating": "(Volume: 8, Issue: 8, August 2023)",
    "venueLink": "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369",
    "bibtex": "@ARTICLE{10147348,\n author={Qiu, Quecheng and Zhang, Xuyang and Yao, Shunyi and Chen, Yu'an and Chen, Guangda and Hua, Bei and Ji, Jianmin},\n journal={IEEE Robotics and Automation Letters},\n title={Training a Non-Cooperator to Identify Vulnerabilities and Improve Robustness for Robot Navigation},\n year={2023},\n volume={8},\n number={8},\n pages={4465-4472},\n keywords={Robots;Navigation;Robot sensing systems;Collision avoidance;Training;Robustness;Legged locomotion;Reinforcement learning;collision avoidance},\n doi={10.1109/LRA.2023.3284379}\n}",
    "abstract": "Autonomous mobile robots have become popular in various applications coexisting with humans, which requires robots to navigate efficiently and safely in crowd environments with diverse pedestrians. Pedestrians may cooperate with the robot by avoiding it actively or ignoring the robot during their walking, while some pedestrians, denoted as non-cooperators, may try to block the robot. It is also challenging to identify potential vulnerabilities of a navigation policy, i.e., situations that the robot may cause a collision, in various crowd environments, which reduces the reliability and the safety of the robot. In this letter, we propose a deep reinforcement learning (DRL) approach to train a policy simulating the behavior of non-cooperators, which can effectively identify vulnerabilities of a navigation policy. We evaluate the approach both on the Robot Operating System (ROS) navigation stack with dynamic window approach (DWA) and a DRL-based navigation policy, which identifies useful vulnerabilities of both navigation policies for further improvements. Moreover, these non-cooperators play a game with the DRL-based navigation policy, then we can improve the robustness of such navigation policy by retraining it in the sense of asymmetric self-play. We evaluate the retrained navigation policy in various crowd environments with diverse pedestrians. The experimental results show that the approach can improve the robustness of the navigation policy.",
    "keywords": "Reinforcement learning, collision avoidance",
    "pdf": "pdf/Training_a_Non-Cooperator_to_Identify_Vulnerabilities_and_Improve_Robustness_for_Robot_Navigation.pdf"
  },
  {
    "title": "Reinforcement Learning for Robot Navigation with Adaptive Forward Simulation Time (AFST) in a Semi-Markov Model",
    "link": "https://ieeexplore.ieee.org/abstract/document/10341985",
    "authors": "Yu'an Chen, Ruosong Ye, Ziyang Tao, Hongjian Liu, <b>Guangda Chen</b>, Jie Peng, Jun Ma, Yu Zhang, Jianmin Ji and Yanyong Zhang.",
    "venue": "IROS 2023",
    "venueLink": "https://ieeexplore.ieee.org/xpl/conhome/10341341/proceeding",
    "rating": "(TH-B)",
    "rating_link": "https://numbda.cs.tsinghua.edu.cn/~yuwj/TH-CPL.pdf#page=12",
    "bibtex": "@inproceedings{chen2023reinforcement,\n title={Reinforcement learning for robot navigation with adaptive forward simulation time (afst) in a semi-markov model},\n author={Chen, Yu'an and Ye, Ruosong and Tao, Ziyang and Liu, Hongjian and Chen, Guangda and Peng, Jie and Ma, Jun and Zhang, Yu and Ji, Jianmin and Zhang, Yanyong},\n booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},\n pages={3597--3604},\n year={2023},\n organization={IEEE}\n}",
    "abstract": "Deep reinforcement learning (DRL) algorithms have proven effective in robot navigation, especially in unknown environments, by directly mapping perception inputs into robot control commands. However, most existing methods ignore the local minimum problem in navigation and thereby cannot handle complex unknown environments. In this paper, we propose the first DRL-based navigation method modeled by a semi-Markov decision process (SMDP) with continuous action space, named Adaptive Forward Simulation Time (AFST), to overcome this problem. Specifically, we reduce the dimensions of the action space and improve the distributed proximal policy optimization (DPPO) algorithm for the specified SMDP problem by modifying its GAE to better estimate the policy gradient in SMDPs. Experiments in various unknown environments demonstrate the effectiveness of AFST.",
    "pdf": "pdf/Reinforcement_Learning_for_Robot_Navigation_with_Adaptive_Forward_Simulation_Time_AFST_in_a_Semi-Markov_Model.pdf",
    "demo": "https://youtu.be/pgP5BQHFum4"
  }
]